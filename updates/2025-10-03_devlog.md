## 2025-10-03 â€” Streaming Chat Refactor (Convex httpAction + AI SDK useChat)

Summary
- Implemented true token-by-token streaming via Convex httpAction and Vercel AI SDK useChat.
- Added new backend endpoint and refactored frontend chat context; dev proxy to avoid CORS.
- Fixed TS types for provider init and onFinish handling per AI SDK v5.

Changes
- Backend:
  - Added: ea-ai-main2/ea-ai-main2/convex/ai/stream.ts (httpAction using streamText; persists onFinish).
  - Updated: ea-ai-main2/ea-ai-main2/convex/http.ts (register POST /chat -> stream action).
- Frontend:
  - Updated: ea-ai-main2/ea-ai-main2/src/context/chat.tsx (switch to @ai-sdk/react useChat; Clerk auth header; normalize messages).
  - Updated: ea-ai-main2/ea-ai-main2/vite.config.ts (proxy /convex-http/* to Convex dev).

Notes
- onFinish must be passed to streamText (finish.response.messages), not to toUIMessageStreamResponse.
- Google Vertex provider used via providerClient.any().chat(modelName) pattern mirroring session.ts.
- Persisted assistant message uses messageSchemas.createEmbeddedMessage.

Next
- Validate tool call/result embedding in persisted history.
- Expand error telemetry and usage metrics.

