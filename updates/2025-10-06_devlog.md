## 2025-10-06 ‚Äî Tool message content investigation (00:04)

**Status**: ‚ö†Ô∏è Partial fixes attempted; HTTP 422 errors persist

### Problem
AI assistant failing with HTTP 422 from xAI/OpenRouter API: "messages[5]: missing field `content`".
Tool messages sent to API have `content: undefined`, violating OpenAI specification requirements.

### Investigation Trail

**Attempted Fix #1**: Updated `simpleMessages.ts:118-128` to structure tool output in UIMessage parts
- Changed `output: matchingResult.result` ‚Üí `output: { type: 'json', value: result }`
- Added safety validation to catch unstructured outputs
- Rationale: Believed issue was in how stored messages were being replayed
- Result: ‚ùå Error persists; this fix addresses message replay, not live streaming

**Attempted Fix #2**: Modified `toolRegistry.ts:180-188` execute function to return string directly
- Changed from returning `{ title, metadata, output }` object to returning plain output string
- Rationale: AI SDK needs raw content value for tool message `content` field
- Result: ‚ùå Error persists; tool message still has `content: undefined`

**Attempted Fix #3**: Removed `type: 'function'` from tool config (line 150)
- Simplified tool structure to match AI SDK v5 expectations
- Result: ‚ö†Ô∏è Uncertain; requires testing after Convex reload

### Current Understanding
The tool executes successfully (logs show "üîß [TOOLS] Called: getCurrentTime"), but when AI SDK 
creates the tool message for the next model request, it sets `content: undefined`. This suggests:
1. The execute return value may not be what AI SDK expects for content field
2. The `experimental_toToolResultContent` function might be interfering
3. Tool config structure might have v4/v5 API conflicts
4. OpenRouter/xAI provider may have strict content requirements vs other providers

### Evidence from Logs (23:57:23)
```
[STREAM][finish] toolCallCount: 1, toolResultCount: 1, assistantPreview: 'I've got it.'
[STREAM] Provider error: messages[5]: missing field `content`
```
- Tool executes (count=1), result captured (count=1)
- Backend completes successfully  
- Next request to API includes tool message with undefined content
- API rejects request before model processes it

### Files Modified
- `convex/ai/simpleMessages.ts:118-166` - Structured tool outputs in UIMessage parts with validation
- `convex/ai/toolRegistry.ts:180-188` - Return string from execute function
- `convex/ai/toolRegistry.ts:150` - Removed `type: 'function'` from tool config  
- `convex/ai/toolRegistry.ts:243` - Removed `as any` cast from aiTool wrapper

### Next Steps
1. Add debug logging to trace actual return value from execute function
2. Remove or comment out `experimental_toToolResultContent` and `toModelOutput` functions
3. Test with minimal tool config structure (description, parameters, execute only)
4. Compare tool structure with working AI SDK v5 examples
5. Consider testing with OpenAI provider to isolate xAI-specific requirements
6. Check if multi-step tool calling (stopWhen: stepCountIs(8)) is causing message format issues

### Impact
- User-visible: All tool-based queries fail (time, calendar, tasks)
- System: Assistant cannot execute any tools; only plain text conversations work  
- Blocking: Critical functionality broken until resolved

## HTTP 422 resolved ‚Äî tool message content fix (later)

**Status**: ‚úÖ Fixed; streaming with tools works without provider errors

### Changes Made
- convex/ai/toolRegistry.ts: Added `toModelOutput(result)` that always returns `{ type: 'text', value: <string> }` ensuring provider-facing role:'tool' messages have non-empty content.
- convex/ai/simpleMessages.ts: Emit tool part outputs as plain strings (v4-compatible) instead of `{ type, value }` objects for history replay.

### Result
- Verified end-to-end via streaming: no more `422 messages[i]: missing field content`; `toolCallCount`/`toolResultCount` logged and assistant reply produced.
- Behavior aligned with opencode reference (pair tool calls/results; no empty tool-role messages).

### Notes
- We retained assistant-embedded toolCalls/toolResults in DB; AI SDK constructs the provider tool message from `toModelOutput` at runtime.
